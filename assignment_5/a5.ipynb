{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with setup by importing the data and normalizing all features by z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import umap\n",
    "\n",
    "SEED = 98532\n",
    "\n",
    "df_read = pd.read_table(\"seeds.tsv\", header=None)\n",
    "\n",
    "# normalize to z-scores\n",
    "scalar = StandardScaler()\n",
    "df = pd.DataFrame(scalar.fit_transform(df_read.iloc[:, :7]))\n",
    "\n",
    "# add labels column back in\n",
    "df = df.assign(**{\"label\": df_read.iloc[:, 7]})\n",
    "df.columns = df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing how many of each type of flower are present in the dataset. This did not end up being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_each_label = {}\n",
    "for i in range (1, 4):\n",
    "    num_each_label[i] = len(df.loc[df[\"label\"] == i])\n",
    "num_each_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating and plotting the inertias for k-means where k is from 1 - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for i in range(1,8):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=SEED).fit(df)\n",
    "    inertia += [kmeans.inertia_]\n",
    "\n",
    "# elbow plot\n",
    "plt.scatter(range(1, len(inertia) + 1), inertia)\n",
    "plt.plot(range(1, len(inertia) + 1), inertia)\n",
    "plt.xlabel(\"Number of Means in k-means\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"\\\"Elbow Plot\\\" of Inertia by k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting each feature compared to every other feature in a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    1: \"red\",\n",
    "    2: \"green\",\n",
    "    3: \"blue\"\n",
    "}\n",
    "\n",
    "for i in range(1, 7 + 1):\n",
    "    for j in range(1, 7 + 1):\n",
    "        if (j <= i):\n",
    "            continue\n",
    "        plt.subplot(7, 7, (i - 1) * 7 + j)\n",
    "        plt.scatter(df.iloc[:, i - 1], df.iloc[:, j - 1], c=df[\"label\"].map(color_map), s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the feature combination that stood out the most individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# i = 1, j = 7 was the best\n",
    "plt.scatter(df.iloc[:, 0], df.iloc[:, 6], c=df[\"label\"].map(color_map), s=5)\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 7\")\n",
    "plt.title(\"Relationship Between Select Features of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Gaussian Random Projection to reduce our data to be visualized in 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = GaussianRandomProjection(n_components=2, random_state=SEED)\n",
    "df_random = transformer.fit_transform(df.iloc[:, :7])\n",
    "\n",
    "# the green is pretty clustered, but the red and blue are mixing significantly\n",
    "# when not seeding, there was an occasional good one, but most were pretty mixed up\n",
    "plt.scatter(df_random[:, 0], df_random[:, 1], c=df[\"label\"].map(color_map))\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Sample Features Projected in 2 Dimensions by Gaussian Random Projection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using UMAP to reduce our data to be visualized in 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(random_state=SEED)\n",
    "df_umap = reducer.fit_transform(df.iloc[:, :7])\n",
    "plt.scatter(df_umap[:, 0], df_umap[:, 1], c=df[\"label\"].map(color_map))\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"Sample Features Projected in 2 Dimensions by UMAP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the accuracy and Rand-index of our 3-means clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=SEED).fit(df)\n",
    "k_labels = kmeans.labels_\n",
    "\n",
    "same_cluster = np.zeros((df.shape[0], df.shape[0]))\n",
    "\n",
    "for i in range(0, same_cluster.shape[0]):\n",
    "    for j in range(0, same_cluster.shape[1]):\n",
    "        if (i >= j):\n",
    "            continue\n",
    "\n",
    "        if (k_labels[i] == k_labels[j]):\n",
    "            same_cluster[i][j] += 1\n",
    "        if (df.iloc[i, :][\"label\"] == df.iloc[j, :][\"label\"]):\n",
    "            same_cluster[i][j] += 1\n",
    "\n",
    "same = 0\n",
    "for i in range(0, same_cluster.shape[0]):\n",
    "    for j in range(0, same_cluster.shape[1]):\n",
    "        if (i >= j):\n",
    "            continue\n",
    "\n",
    "        if (same_cluster[i][j] != 1):\n",
    "            same += 1\n",
    "\n",
    "# finding the correct clustering by taking the clusters that are most commonly correct -- assumes that the model doesnt completely suck\n",
    "correct_cluster = np.zeros((3, 3))\n",
    "for i in range(0, same_cluster.shape[0]):\n",
    "    correct_cluster[k_labels[i]][(df.iloc[i, :][\"label\"] - 1).astype(np.int32)] += 1\n",
    "num_correct_cluster = 0\n",
    "for i in range(0, correct_cluster.shape[0]):\n",
    "    largest = correct_cluster[i][0]\n",
    "    for j in range(1, correct_cluster[i].shape[0]):\n",
    "        if correct_cluster[i][j] > largest:\n",
    "            largest = correct_cluster[i][j]\n",
    "    num_correct_cluster += largest\n",
    "\n",
    "num_items = same_cluster.shape[0]\n",
    "\n",
    "rand_index = same / ((pow(num_items, 2) - num_items) / 2)\n",
    "accuracy = num_correct_cluster / num_items\n",
    "\n",
    "rand_index, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a hierarchal clustering of the samples by using Complete linkage with Euclidean distance, and graphing the dendrogram. Original labels are placed under the corresponding leaf. Except for one noticable section, for the most part, the clusters here are quite accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_arr = np.array(df[\"label\"])\n",
    "linkage_matrix = linkage(df, method=\"complete\", metric=\"euclidean\")\n",
    "dendrogram(linkage_matrix, labels=labels_arr)\n",
    "plt.title(\"Dendrogram of Samples Clustered with Complete Linkage\")\n",
    "plt.xlabel(\"Original Label in Dataset\")\n",
    "plt.ylabel(\"Euclidean Distance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
