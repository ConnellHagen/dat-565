{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying an image from the training set as a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying an image from the test set as a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = next(iter(test_dataloader))\n",
    "img = test_features[0].squeeze()\n",
    "label = test_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture for the one layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_NEURONS = 200\n",
    "\n",
    "class OneLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneLayer, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(28 * 28, L1_NEURONS)\n",
    "        self.fc2 = nn.Linear(L1_NEURONS, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x));\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneLayer()\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training and evaluating the one layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "running_loss = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, data in tqdm(enumerate(train_dataloader)):\n",
    "        model.train()\n",
    "\n",
    "        inputs, labels = data\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        flattened_inputs = inputs.view(inputs.size(0), -1)\n",
    "        outputs = model(flattened_inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {e}: Average loss of {running_loss / 64} per batch\")\n",
    "    running_loss = 0\n",
    "\n",
    "    # test benchmark\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (inputs, labels) in tqdm(enumerate(test_dataloader)):\n",
    "        flattened_inputs = inputs.view(inputs.size(0), -1)\n",
    "\n",
    "        outputs = model(flattened_inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    print(f\"Epoch {e}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/one_layer_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture for the two layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_NEURONS = 500\n",
    "L2_NEURONS = 300\n",
    "\n",
    "class TwoLayers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayers, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(28 * 28, L1_NEURONS)\n",
    "        self.fc2 = nn.Linear(L1_NEURONS, L2_NEURONS)\n",
    "        self.fc3 = nn.Linear(L2_NEURONS, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoLayers()\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), weight_decay=1e-4, lr=0.01) # weight decay for L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and evaluating the two layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "running_loss = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, data in tqdm(enumerate(train_dataloader)):\n",
    "        model.train()\n",
    "\n",
    "        inputs, labels = data\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        flattened_inputs = inputs.view(inputs.size(0), -1)\n",
    "        outputs = model(flattened_inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {e}: Average loss of {running_loss / 64} per batch\")\n",
    "    running_loss = 0\n",
    "\n",
    "    # test benchmark\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (inputs, labels) in tqdm(enumerate(test_dataloader)):\n",
    "        flattened_inputs = inputs.view(inputs.size(0), -1)\n",
    "\n",
    "        outputs = model(flattened_inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    print(f\"Epoch {e}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/2-layer-0-01-learning-rate.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture for the convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_OUTPUT_CHANNELS = 16\n",
    "L2_OUTPUT_CHANNELS = 32\n",
    "\n",
    "class ConvNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetwork, self).__init__()\n",
    "\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=L1_OUTPUT_CHANNELS, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=L1_OUTPUT_CHANNELS, out_channels=L2_OUTPUT_CHANNELS, kernel_size=3, padding=1)\n",
    "\n",
    "        # pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # fully-connected layers\n",
    "        self.fc1 = nn.Linear(L2_OUTPUT_CHANNELS * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, L2_OUTPUT_CHANNELS * 7 * 7) # flatten images\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNetwork()\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), weight_decay=1e-5, lr=0.01) # weight decay for L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training and evaluating the convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "running_loss = 0\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, data in tqdm(enumerate(train_dataloader)):\n",
    "        model.train()\n",
    "\n",
    "        inputs, labels = data\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {e}: Average loss of {running_loss / 64} per batch\")\n",
    "    running_loss = 0\n",
    "\n",
    "    # test benchmark\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (inputs, labels) in tqdm(enumerate(test_dataloader)):\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    print(f\"Epoch {e}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/conv-network.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
